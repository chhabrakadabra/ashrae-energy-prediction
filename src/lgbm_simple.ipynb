{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "Q: How much does it cost to cool a skyscraper in the summer?\n",
    "A: A lot! And not just in dollars, but in environmental impact.\n",
    "\n",
    "Thankfully, significant investments are being made to improve building efficiencies to reduce costs and emissions. The question is, are the improvements working? That’s where you come in. Under pay-for-performance financing, the building owner makes payments based on the difference between their real energy consumption and what they would have used without any retrofits. The latter values have to come from a model. Current methods of estimation are fragmented and do not scale well. Some assume a specific meter type or don’t work with different building types.\n",
    "\n",
    "In this competition, you’ll develop accurate models of metered building energy usage in the following areas: chilled water, electric, hot water, and steam meters. The data comes from over 1,000 buildings over a three-year timeframe. With better estimates of these energy-saving investments, large scale investors and financial institutions will be more inclined to invest in this area to enable progress in building efficiencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about codestyle\n",
    "\n",
    "In Jupyter notebooks, the emphasis is on quick experimentation. The quality of the code is not what we optimize for. So when \"productionizing\" this notebook, take everything with a grain of salt and rethink the structure of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data is available on the file system in `../input/ashrae-energy-prediction`. Let's just list it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "BASE_DIR = Path('..').resolve()\n",
    "DATA_DIR = BASE_DIR / 'input' / 'ashrae-energy-prediction'\n",
    "print(os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of files\n",
    "\n",
    "(pasted from https://www.kaggle.com/c/ashrae-energy-prediction/data)\n",
    "\n",
    "### train.csv\n",
    "* `building_id` - Foreign key for the building metadata.\n",
    "* `meter` - The meter id code. Read as `{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}`. Not every building has all meter types.\n",
    "* `timestamp` - When the measurement was taken\n",
    "* `meter_reading` - The target variable. Energy consumption in kWh (or equivalent). Note that this is real data with measurement error, which we expect will impose a baseline level of modeling error. UPDATE: as discussed here, the site 0 electric meter readings are in kBTU.\n",
    "\n",
    "### building_meta.csv\n",
    "* `site_id` - Foreign key for the weather files.\n",
    "* `building_id` - Foreign key for training.csv\n",
    "* `primary_use` - Indicator of the primary category of activities for the building based on EnergyStar property type definitions\n",
    "* `square_feet` - Gross floor area of the building\n",
    "* `year_built` - Year building was opened\n",
    "* `floor_count` - Number of floors of the building\n",
    "\n",
    "### weather_[train/test].csv\n",
    "Weather data from a meteorological station as close as possible to the site.\n",
    "\n",
    "* `site_id`\n",
    "* `air_temperature` - Degrees Celsius\n",
    "* `cloud_coverage` - Portion of the sky covered in clouds, in oktas\n",
    "* `dew_temperature` - Degrees Celsius\n",
    "* `precip_depth_1_hr` - Millimeters\n",
    "* `sea_level_pressure` - Millibar/hectopascals\n",
    "* `wind_direction` - Compass direction (0-360)\n",
    "* `wind_speed` - Meters per second\n",
    "\n",
    "### test.csv\n",
    "The submission files use row numbers for ID codes in order to save space on the file uploads. `test.csv` has no feature data; it exists so you can get your predictions into the correct order.\n",
    "\n",
    "* `row_id` - Row id for your submission file\n",
    "* `building_id` - Building id code\n",
    "* `meter` - The meter id code\n",
    "* `timestamp` - Timestamps for the test data period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def load_df(fname):\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "    if 'timestamp' in df.columns:\n",
    "        # I guess fortunately all timestamp columns are called `timestamp`.\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(load_df('train.csv'))\n",
    "building_metadata_df = reduce_mem_usage(load_df('building_metadata.csv'))\n",
    "weather_train_df = reduce_mem_usage(load_df('weather_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis, minor cleanup and feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def describe_df(df):\n",
    "    print('Shape of data: ', df.shape)\n",
    "    print('\\nBasic info:')\n",
    "    print(df.info())\n",
    "    print('\\nQuick peek at the data:')\n",
    "    print(df.head())\n",
    "    print('\\nBasic description of the data:')\n",
    "    print(df.describe())\n",
    "    print('\\nLooking at NAs')\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: `train_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NAs in `train_df`, so that's nice. The timestamps have been treated well. The memory consumption is modest, so there's no need to mess around with that.\n",
    "\n",
    "It's worth looking at the meter readings as timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The duration of the training data\n",
    "train_df['timestamp'].min(), train_df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='timestamp', y='meter_reading', hue='meter', kind='line', \n",
    "            palette=sns.color_palette('hls', 4), aspect=16/9, height=10,\n",
    "            data=(train_df\n",
    "                  .groupby(by=['meter', 'timestamp'])\n",
    "                  .agg({'meter_reading': 'median'}).reset_index()))\n",
    "plt.xticks(rotation=15)\n",
    "plt.title('Median meter readings over time for different meter types')\n",
    "plt.gca().set(yscale='log')\n",
    "plt.ylabel('Meter reading (log-scale)')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The `meter_reading` column is in log-scale above. The outputs of meter type `2` are much higher than the rest, so it's easier to see patterns in log-scale.\n",
    "\n",
    "In the plot above, we can see that the meter type is obviously an important feature. In addition, clearly the `meter_reading` has plenty of seasonality. The most evident examples of seasonality here are based on time of day and day of week and that seasonality is different for different meter types.\n",
    "\n",
    "For example, notice that meter `0` is clearly affected by weekend vs. weekday dynamics more so than other meter types. There are probably also monthly seasonal effects based on heating needs being different in winter vs. summer, although that's not visible in the graph above. To see that aspect of seasonality look at the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='month_of_year', y='meter_reading', hue='meter', kind='line', \n",
    "            palette=sns.color_palette('hls', 4), aspect=16/9,\n",
    "            data=(train_df\n",
    "                  .assign(month_of_year=train_df['timestamp'].dt.month)\n",
    "                  .groupby(by=['meter', 'month_of_year'])\n",
    "                  .agg({'meter_reading': 'median'}).reset_index()))\n",
    "plt.xticks(rotation=15)\n",
    "plt.title('Median meter readings over months for different meter types (1 year)')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've concluded that the meter type, the hour of day, the day of week, the day of year are potentially useful features. So let's add those to the `train_df` dataframe.\n",
    "\n",
    "# Outlier detection\n",
    "\n",
    "Another thing worth noting is that there are plenty of outliers especially for meter IDs `1` and `3`. Let's try to understand what's going on there. Let's start with meter ID `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['meter'] == 3]['building_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for meter in range(4):\n",
    "    sns.distplot(train_df[train_df['meter'] == meter].groupby('building_id').agg({'meter_reading': 'std'})['meter_reading'], rug=True)\n",
    "    plt.title(meter)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for building_id in train_df[train_df['meter'] == 3]['building_id'].unique()[:10]:\n",
    "    sns.distplot(train_df[train_df['building_id'] == building_id]['meter_reading'], rug=True)\n",
    "    print('Std. deviation is: ', train_df[train_df['building_id'] == building_id]['meter_reading'].std())\n",
    "    plt.title(building_id)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='building_id', y='meter_reading', data=train_df[train_df['meter'] == 3].groupby(by='building_id').agg({'meter_reading': 'sum'}).sort_values('meter_reading').reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation: `train_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(hour_of_day=train_df['timestamp'].dt.hour, \n",
    "                           day_of_week=train_df['timestamp'].dt.dayofweek,\n",
    "                           month_of_year=train_df['timestamp'].dt.month,\n",
    "                           day_of_year=train_df['timestamp'].dt.dayofyear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: `building_metadata.csv`\n",
    "\n",
    "The `train_df` dataframe had a `building_id` column that we never investigated. Let's do that now, combined with the `building_metadata.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(building_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems here is that the columns `year_built` and `floor_count` have plenty of null values. For now, I'm planning to leave them as is. Lightgbm can handle null values, so we'll rely on that for now. \n",
    "\n",
    "It would be interesting to see how both `square_feet`, `primary_use` and `year_built` influence `energy_consumption`.\n",
    "\n",
    "But before we get into that, we should adjust `train_df`. Remember that the instructions on the dataset say that \"the site 0 electric meter readings are in kBTU.\". Now that we have the `building_metadata_df` dataframe, we can fix that up. Note that to convert from kBTU to kWh, you divide by 3.412."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.merge(building_metadata_df, on=['building_id']).pipe(lambda df: df['site_id'] == 0), 'meter_reading'] /= 3.412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between `square_feet` and energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x='square_feet', y='meter_reading', height=8,\n",
    "                  data=(train_df.groupby(by='building_id')\n",
    "                        .agg({'meter_reading': 'median'})\n",
    "                        .join(building_metadata_df, on=['building_id'])))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that there doesn't seem to be much of a linear relationship between `square_feet` and the `meter_reading`. What's more interesting is that the relationship is more evident in log-log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x='square_feet', y='meter_reading', height=8, kind='reg',\n",
    "                  data=(train_df.groupby(by='building_id')\n",
    "                        .agg({'meter_reading': 'median'})\n",
    "                        .join(building_metadata_df, on=['building_id'])\n",
    "                        .pipe(lambda df: df.assign(meter_reading=np.log1p(df.meter_reading),\n",
    "                                                   square_feet=np.log1p(df.square_feet)))))\n",
    "g.ax_joint.set_xlabel('Meter reading (log-scale)')\n",
    "g.ax_joint.set_ylabel('Square feet (log-scale)')\n",
    "g.fig.suptitle('Relationship between Square footage and energy consumption in log-log space')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between `primary_use` and energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 20))\n",
    "sns.violinplot(x='meter_reading', y='primary_use', orient='h', scale='count',\n",
    "               data=(train_df.groupby(by='building_id')\n",
    "                     .agg({'meter_reading': 'median'})\n",
    "                     .join(building_metadata_df, on=['building_id'])))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could have been expected, the distributions of energy consumption for various types of buildings is different. Since the violin plots are scaled by the count of datapoints, it means that most of the data in the training set is for education buildings.\n",
    "\n",
    "### Relationship between `year_built` and energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='year_built', y='meter_reading',\n",
    "             data=(train_df\n",
    "                   .merge(building_metadata_df, on=['building_id'])\n",
    "                   .groupby(by='year_built')\n",
    "                   .agg({'meter_reading': 'median'})\n",
    "                   .reset_index()))\n",
    "plt.title('Meter readings for buildings built in different years')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the median meter reading for buildings built during different years is very different. So of course the year_built is an important feature. Perhaps it would be appropriate to keep it a categorical feature. \n",
    "\n",
    "### Relationship between `site_id` and energy consumption\n",
    "\n",
    "It might be interesting to see how the energy consumption changes by site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='timestamp', y='meter_reading', hue='site_id', kind='line',\n",
    "            palette=sns.color_palette('hls', 16), aspect=16/9, height=10,\n",
    "            data=(train_df\n",
    "                  .merge(building_metadata_df, on=['building_id'])\n",
    "                  .groupby(by=['site_id', 'timestamp'])\n",
    "                  .agg({'meter_reading': 'sum'})\n",
    "                  .reset_index()))\n",
    "plt.gca().set(yscale='log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be something fishy going on with a few of the sites. There seem to be a few dramatic jumps. It's worth keeping an eye out on this. Perhaps the data is very unclean? Perhaps it would be better to just get rid of this faulty data?\n",
    "\n",
    "Let's start by looking at a few problematic sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='timestamp', y='meter_reading', hue='meter', kind='line',\n",
    "            aspect=16/9, height=10,\n",
    "            data=(train_df\n",
    "                  .merge(building_metadata_df, on=['building_id'])\n",
    "                  .pipe(lambda df: df[df['site_id'] == 0])\n",
    "                  .groupby(by=['meter', 'timestamp'])\n",
    "                  .agg({'meter_reading': 'sum'})\n",
    "                  .reset_index()))\n",
    "plt.gca().set(yscale='log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further analysis, it looks like all data for site `0` and meter `0` on or before `2016-05-20` has something funny going on. Rather than take a guess as to what is going on with it, I'm just going to get rid of it. I'll be going it in a later section once I merge all the dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's definitely something wrong with the data for site_id `0` meter type `0` for the first bit of the data. Might be best to get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='timestamp', y='meter_reading', hue='meter', kind='line',\n",
    "            aspect=16/9, height=10,\n",
    "            data=(train_df\n",
    "                  .merge(building_metadata_df, on=['building_id'])\n",
    "                  .pipe(lambda df: df[df['site_id'] == 15])\n",
    "                  .groupby(by=['meter', 'timestamp'])\n",
    "                  .agg({'meter_reading': 'sum'})\n",
    "                  .reset_index()))\n",
    "plt.gca().set(yscale='log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there's something funny going on with site `15` meter `1` between and including dates `2016-02-10` and `2016-03-24`. Going to get rid of that when we merge the dataframes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation: `building_metadata.csv`\n",
    "\n",
    "For now, we definitely want to encode the 2 categorical variables: `year_built` and `primary_use`. We also want to log-transform the `square_feet` column because of our previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_metadata_enc = {\n",
    "    'year_built': LabelEncoder(),\n",
    "    'primary_use': LabelEncoder(),\n",
    "}\n",
    "building_metadata_df['year_built_enc'] = (building_metadata_enc['year_built']\n",
    "                                          .fit_transform(building_metadata_df['year_built']))\n",
    "building_metadata_df['primary_use_enc'] = (building_metadata_enc['primary_use']\n",
    "                                           .fit_transform(building_metadata_df['primary_use']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_metadata_df['square_feet_log'] = np.log1p(building_metadata_df['square_feet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: `weather_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(weather_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lot of nans here. We might have to do some imputation for weather. Plus, we don't even know if all the hours starting from the smallest in the dataframe to the largest have values here. We should check that out first.\n",
    "\n",
    "### Checking time-gaps in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datetime_range = pd.date_range(start=train_df['timestamp'].min(), end=train_df['timestamp'].max(), freq='H')\n",
    "sites = building_metadata_df['site_id'].unique()\n",
    "weather_train_idx = pd.MultiIndex.from_product([training_datetime_range, sites], names=['timestamp', 'site_id'])\n",
    "\n",
    "weather_train_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `weather_train_idx` index has a length larger than that of `weather_train_df`. This implies that there are gaps in the weather information. Let's expand the `weather_train_df` dataframe to account for those gaps first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df = pd.merge(left=pd.DataFrame(index=weather_train_idx).reset_index(), \n",
    "                            right=weather_train_df, how='left', on=['timestamp', 'site_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing weather information\n",
    "\n",
    "We can use `interpolate` to impute values. We do so within the context of each `site_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df = pd.concat([site_weather_train_df.sort_values('timestamp').interpolate(limit_direction='both')\n",
    "                             for _, site_weather_train_df in weather_train_df.groupby('site_id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(weather_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the columns still have plenty of NAs. The only explanation for it is that this must be for sites that have no data for those columns. Let's just double check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df[weather_train_df['cloud_coverage'].isna()]['site_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_train_df[weather_train_df['site_id'] == 7]['cloud_coverage'].shape)\n",
    "print(weather_train_df[weather_train_df['site_id'] == 7]['cloud_coverage'].isna().sum())\n",
    "print(weather_train_df[weather_train_df['site_id'] == 11]['cloud_coverage'].shape)\n",
    "print(weather_train_df[weather_train_df['site_id'] == 11]['cloud_coverage'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no wonder that all the number of NAs in the post-interpolation `weather_train_df` are multiples of `8784`. We'll just not use these columns for now in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all the dataframes\n",
    "\n",
    "Before we do the analysis of the relationship of the various weather parameters to the meter reading, it might be beneficial to merge the dataframes, so we can get ahead of this expensive operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (train_df\n",
    "             .merge(building_metadata_df, on=['building_id'])\n",
    "             .merge(weather_train_df, on=['site_id', 'timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, I'm going to get rid of the training data for:\n",
    "\n",
    "* site_id `0` and meter `0` on and before `2016-05-20`.\n",
    "* site_id `15` and meter `1` between (and including) `2016-02-10` and `2016-03-24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[(merged_df['site_id'] != 0) | (merged_df['meter'] != 0) | (merged_df['timestamp'] > pd.to_datetime('2016-05-20'))]\n",
    "merged_df = merged_df[(merged_df['site_id'] != 15) | (merged_df['meter'] != 1) | (merged_df['timestamp'] < pd.to_datetime('2016-02-10')) | (merged_df['timestamp'] > pd.to_datetime('2016-03-24'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between `air_temperature` and `meter_reading`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=merged_df.assign(meter_reading=np.log1p(merged_df.meter_reading)), kind='hex',\n",
    "              x='air_temperature', y='meter_reading')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primary_use, group_df in merged_df.groupby('primary_use'):\n",
    "    sns.jointplot(data=group_df.assign(meter_reading=np.log1p(group_df.meter_reading)), kind='hex', \n",
    "                  x='air_temperature', y='meter_reading')\n",
    "    plt.title(primary_use)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presumably there are plenty of moments where the various buildings are just not in use and it doesn't matter how hot or cold it is outside. So we should ignore the low `meter_reading` data points. Also, we'll stick to using log-space for meter readings because we've decided that the strong correlation between `square_feet` and `meter_reading` in log-log space is useful for us.\n",
    "\n",
    "It doesn't look like there's a very clear relationship between the 2 variables. The shape is mostly a blob, but there are density differences in the blob. When split across primary_use, we start to see some patterns for some of the primary usages, but nothing that's very clear. So might be okay to keep the variable in, but I'm not expecting much from it.\n",
    "\n",
    "### Relationship between `dew_temperature` and `meter_reading`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=merged_df.assign(meter_reading=np.log1p(merged_df.meter_reading)), kind='hex',\n",
    "              x='dew_temperature', y='meter_reading')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primary_use, group_df in merged_df.groupby('primary_use'):\n",
    "    sns.jointplot(data=group_df.assign(meter_reading=np.log1p(group_df.meter_reading)), kind='hex', \n",
    "                  x='dew_temperature', y='meter_reading')\n",
    "    plt.title(primary_use)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole thing also looks very similar to `air_temperature`. Perhaps worth keeping this in as well, but low expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between `dew_temperature / air_temperature` and `meter_reading`\n",
    "\n",
    "> The dew point is the temperature to which air must be cooled to become saturated with water vapor.\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/Dew_point\n",
    "\n",
    "This indicates that there might be a relationship between this ratio and `meter_reading`. Also, since `air_temperature` can hit zero, we can have an issue with infinities. So let's switch to Kelvins for temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=merged_df.assign(meter_reading=np.log1p(merged_df.meter_reading), \n",
    "                                    temp_ratio=(merged_df.dew_temperature + 273.16) / (merged_df.air_temperature + 273.16)), \n",
    "              kind='hex',\n",
    "              x='temp_ratio', y='meter_reading')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's almost no relationship between these 2 variables.\n",
    "\n",
    "### Relationship between `cloud_coverage` and `meter_reading`\n",
    "\n",
    "`cloud_coverage` data is empty quite often. So let's only plot when it's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=merged_df.assign(meter_reading=np.log1p(merged_df.meter_reading)).dropna(subset=['cloud_coverage']), \n",
    "              kind='hex', x='cloud_coverage', y='meter_reading')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `cloud_coverage` only occurs in discrete values. For each of these values, the distribution is slightly different. Might as well throw this into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data\n",
    "\n",
    "We established earlier that there is value in dealing with the meter_reading in log-space. So we'll do that transformation here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['meter_reading_log'] = np.log1p(merged_df['meter_reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course there are plenty of columns in the `merged_train_df` dataframe that are not required for the actual modeling. So let's select the columns we care for. Let's also make a separate dataframe for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sort_values('timestamp')\n",
    "feature_cols = ['building_id', 'day_of_week', 'month_of_year', 'day_of_year', 'floor_count', \n",
    "                'hour_of_day', 'meter', 'primary_use_enc', 'site_id', \n",
    "                'square_feet_log', 'year_built_enc', 'air_temperature', 'dew_temperature', 'cloud_coverage']\n",
    "categorical_features = ['building_id', 'day_of_week', 'month_of_year', 'day_of_year', 'hour_of_day',\n",
    "                        'meter', 'primary_use_enc', 'site_id', 'year_built_enc']\n",
    "X_df = merged_df[feature_cols]\n",
    "y_df = merged_df[['meter_reading_log']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split methodology\n",
    "\n",
    "The training dataset ranges from `2016-01-01 00:00:00` to `2016-12-31 23:00:00` and the test dataset ranges from `2017-01-01 00:00:00` to `2018-12-31 23:00:00`.\n",
    "\n",
    "So if we split the data for our own train/validation routine, we should also split the data with non-overlapping timestamps. One way to think about it is that the model should learn the day-to-day changes in energy consumption from the seasonality and weather features and not from knowing the changes in energy consumption for the same timestamps for other buildings in the same site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use `sklearn.model_selection.GroupKFold` and define \"groups\" to be based on\n",
    "# the month. Our training dataset has 12 months, and we can choose 3 splits.\n",
    "kfold = GroupKFold(n_splits=3)\n",
    "groups = X_df['month_of_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of other dataframes and save some memory before the real show begins\n",
    "del train_df\n",
    "del weather_train_df\n",
    "del merged_df\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_name = 'models'\n",
    "models = []\n",
    "validation_datasets = []\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1280,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    # The actual metric we'd be measured against is RMLSE \n",
    "    # (https://www.kaggle.com/c/ashrae-energy-prediction/overview/evaluation)\n",
    "    # but since we've already taken the log of the meter reading as the target\n",
    "    # we should just use the RMSE metric.\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "for idx, (train_index, val_index) in enumerate(kfold.split(X_df, y_df, groups)):\n",
    "    X_train_df, y_train_df = X_df.iloc[train_index], y_df.iloc[train_index]\n",
    "    X_val_df, y_val_df = X_df.iloc[val_index], y_df.iloc[val_index]\n",
    "    train_dataset = lgb.Dataset(X_train_df, label=y_train_df, \n",
    "                                categorical_feature=categorical_features)\n",
    "    val_dataset = lgb.Dataset(X_val_df, label=y_val_df,\n",
    "                              categorical_feature=categorical_features)\n",
    "\n",
    "    model_name = str(BASE_DIR / 'output' / f'{model_base_name}_{idx}.txt')\n",
    "    \n",
    "    try:\n",
    "        # Try loading the model from disk\n",
    "        model = lgb.Booster(model_file=model_name)\n",
    "        print(f'Model with name {model_name} found. Skipping training for fold {idx}.')\n",
    "    except lgb.basic.LightGBMError:\n",
    "        # I guess we have to train the model\n",
    "        print(f'Training fold {idx}')\n",
    "        model = lgb.train(params=params, train_set=train_dataset, num_boost_round=1000,\n",
    "                          valid_sets=[val_dataset],\n",
    "                          early_stopping_rounds=50, verbose_eval=25)\n",
    "        print(f'Saving model using name {model_name} for future short-circuiting.')\n",
    "        model.save_model(model_name)\n",
    "    models.append(model)\n",
    "    # Store the predictions of the model on the validation set for analysis later.\n",
    "    validation_datasets.append((X_val_df, y_val_df, model.predict(X_val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    lgb.plot_importance(model)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the models on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_val_dfs = [\n",
    "    X_val_df.assign(y_true=y_val_df, y_pred=y_pred_df).pipe(lambda df: df.assign(error=df['y_pred'] - df['y_true']))\n",
    "    for X_val_df, y_val_df, y_pred_df in validation_datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('Errors (RMSE) for models: ', [mean_squared_error(merged_val_df['y_true'], merged_val_df['y_pred'], squared=False) \n",
    "                                     for merged_val_df in merged_val_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_val_dfs[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merged_val_df in merged_val_dfs:\n",
    "    sns.relplot(x='day_of_year', y='error', hue='site_id', kind='line',\n",
    "                palette=sns.color_palette('hls', merged_val_df['site_id'].nunique()), aspect=16/9, height=10,\n",
    "                data=merged_val_df)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataframes first\n",
    "test_df = reduce_mem_usage(load_df('test.csv'))\n",
    "weather_test_df = reduce_mem_usage(load_df('weather_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.assign(hour_of_day=test_df['timestamp'].dt.hour, \n",
    "                         day_of_week=test_df['timestamp'].dt.dayofweek,\n",
    "                         day_of_year=test_df['timestamp'].dt.dayofyear,\n",
    "                         month_of_year=test_df['timestamp'].dt.month)\n",
    "\n",
    "merged_test_df = (test_df\n",
    "                  .merge(building_metadata_df, how='left', on=['building_id'])\n",
    "                  .merge(weather_test_df, how='left', on=['site_id', 'timestamp']))\n",
    "X_test_df = merged_test_df[feature_cols]\n",
    "row_ids = merged_test_df['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_df\n",
    "del weather_test_df\n",
    "del merged_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = [np.expm1(model.predict(X_test_df)) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_df = pd.DataFrame({'row_id': row_ids, \n",
    "                           'meter_reading': np.vstack(results).T.mean(axis=1).clip(0, None)})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(BASE_DIR / 'output' / 'submission_with_bad_data_removed.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* Why encode year_built? Isn't it already encoded?\n",
    "* Play around with imputing the empty features for the weather data\n",
    "* Play around with month of year vs. day of year\n",
    "* Consider converting site 0 readings to kWh just like the rest\n",
    "* Maybe floor count should be categorical?\n",
    "* Consider removing dates when the totals for a meter_type are zero. What are the odds that all these sites had zero consumption for hot water for a given day?\n",
    "* Instead of k-fold, try a simpler split across time series to see how that performs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
